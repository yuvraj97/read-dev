<!DOCTYPE HTML>
<html lang="en">
    <head>

        <script>
            var isConcluded = true;
            var arrowLeftPage = "/linear-algebra/eigenvalues-eigenvectors/"
            var arrowRightPage = "/linear-algebra/differential-equation/"
        </script>

        <link rel="stylesheet" href="/data/css/main.css">
                
		<title>Diagonalization of a Matrix - QuantML</title>
		<meta charset="utf-8" />
        <link rel="icon" href="/data/icon.png" type="image/png" sizes="16x16">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<meta name="robots" content="index, follow">
        <meta name="author" content="Yuvraj Garg">

        <script src="/data/js/initialize.js"></script>

	</head>   
    
    <body>

        <!-- Wrapper -->
			<div style="display: none;" id="wrapper">
                <div class="bg fixed" style="transform: none;"></div>
                <div id="navPanelToggle">Menu</div>


				<!-- Header -->
				<header id="header">
					<a href="https://quantml.org" style="display: none;" class="logo image jump-big" id="quantml-cover-light"><img src="/data/img/cover.webp" alt="QuantML.org" /></a>
					<a href="https://quantml.org" style="display: none;" class="logo image jump-big" id="quantml-cover-dark"><img src="/data/img-dark/cover.webp" alt="QuantML.org" /></a>
					<script>if(window.quantml["theme"]=="dark") document.getElementById('quantml-cover-dark').style.display = "block";else document.getElementById('quantml-cover-light').style.display = "block";</script>
				</header>

                <!-- Nav -->
                    <nav id="nav">
                        <ul class="links">
                            <li class="cover"><a href="/linear-algebra/"><img src="/data/img/linear-algebra-cover.png" alt="Linear Algebra"></a></li>
                            <li class="active title">Diagonalization of a Matrix</li>
                        </ul>
                        <ul id="nav-bar-icons-head" class="icons"></ul>
                    </nav>

<!-- Main -->
<div id="main">
    <section class="post">
<div style="text-align: center;" id="load-init"></div>
<script>initializeBody();</script>

<div id="paragraph-content" data-swipe-threshold="80">
<div id="btn-container">
    <button id="prev-btn" class="button" onclick="window.location.href = '/linear-algebra/eigenvalues-eigenvectors/';">&#x25C0;&nbsp;&nbsp;Eigenvalues and Eigenvectors</button>
    <button id="next-btn" class="button"  style="float: right;" onclick="window.location.href = '/linear-algebra/differential-equation/';">Differential Equation&nbsp;&nbsp;&#x25B6;</button>
</div><br>


<p>
<h1>Diagonalization of a Matrix</h1>
Say that we have a \(n\times n\) matrix \(A\) with 
\(n\) <b>independent</b> <i>eigenvectors</i> (say \(\vec{x}_1,\vec{x}_2,\cdots,\vec{x}_n\)).<br>
We put these <i>eigenvectors</i> (\(\vec{x}_1,\vec{x}_2,\cdots,\vec{x}_n\)) in a matrix (say \(S\)).<br>
\[
S=\begin{bmatrix}
 \vdots & \vdots & \cdots & \vdots \\  
 \vec{x}_{1} & \vec{x}_{2} & \cdots &  \vec{x}_{n}   \\
 \vdots & \vdots & \cdots & \vdots \\
 \end{bmatrix}
\]
\[A\vec{x}_i=\lambda_i\vec{x}_i;\quad 
\left\{\begin{matrix}
    \vec{x}_i\text{ is eigenvector}\\
    \lambda_i\text{ is eigenvalue}
    \end{matrix}\right.
\]
Let's calculate \(AS\)<br>
<blockquote class="noborder">
\(AS = A \begin{bmatrix}
 \vdots & \vdots & \cdots & \vdots \\  
 \vec{x}_{1} & \vec{x}_{2} & \cdots &  \vec{x}_{n}   \\
 \vdots & \vdots & \cdots & \vdots \\
 \end{bmatrix}\)<br>

\(\Rightarrow AS = \begin{bmatrix}
 \vdots & \vdots & \cdots & \vdots \\  
 A\vec{x}_{1} & A\vec{x}_{2} & \cdots &  A\vec{x}_{n}   \\
 \vdots & \vdots & \cdots & \vdots \\
 \end{bmatrix}\)<br>

\(\Rightarrow AS = \begin{bmatrix}
 \vdots & \vdots & \cdots & \vdots \\  
 \lambda_1\vec{x}_{1} & \lambda_2\vec{x}_{2} & \cdots &  \lambda_n\vec{x}_{n}   \\
 \vdots & \vdots & \cdots & \vdots \\
 \end{bmatrix}\)<br>

 <div class="math-container">
\[\Rightarrow AS = \begin{bmatrix}
 \vdots & \vdots & \cdots & \vdots \\  
 \vec{x}_{1} & \vec{x}_{2} & \cdots & \vec{x}_{n}   \\
 \vdots & \vdots & \cdots & \vdots \\
 \end{bmatrix}
 \underbrace{\begin{bmatrix}
 \lambda_1 &     0     & \cdots  &    0    \\  
 0         & \lambda_2 & \cdots  &    0    \\  
 \vdots    & \vdots    & \ddots  & \vdots    \\  
 0         &    0      & \cdots  &    \lambda_n    \\  
\end{bmatrix}}_{\text{say }\Lambda}
 \]</div>
 </blockquote>

<span class="bb">\(AS=S\Lambda\)</span><br>
because \(S\) has independent columns so \(S^{-1}\) exists, so<br>

<div class="l1 border">
    \[
        \begin{matrix}
            
        % equation
        \displaystyle \Lambda =S^{-1}AS
        %equation

        \end{matrix}
    \]
</div>
    
This is <b>Diagonalization</b>.<br>

We can also get a factorization of \(A\)<br>
<div class="l1 border">
    \[
        \begin{matrix}
            
        % equation
        \displaystyle A=S\Lambda S^{-1}
        %equation

        \end{matrix}
    \]
</div><br>
<br>

<h1 id="power">Power of a matrix</h1>
Now let's see how \(A=S\Lambda S^{-1}\) helps us in calculating \(A^k\) for \(k=\{1,2,3,\cdots\}\)<br>
We know that,<br>
\[A\vec{x}_i=\lambda_i\vec{x}_i;\quad 
\left\{\begin{matrix}
    \vec{x}_i\text{ is eigenvector}\\
    \lambda_i\text{ is eigenvalue}
    \end{matrix}\right.
\]
Now let's calculate <i>eigenvectors</i> and <i>eigenvalues</i> of \(A^2\).<br>
\(AA\vec{x}_i=\lambda_i (A \vec{x}_i)\)<br>
\(\Rightarrow A^2\vec{x}_i=\lambda_i^2\vec{x}_i\)<br>
So <i>eigenvectors</i> of \(A^2\) remains same.<br>
But <i>eigenvalues</i> of \(A^2\) becomes \(\lambda^2\).<br>
<br>
We can also get it by \(A=S\Lambda S^{-1}\).<br>
<blockquote class="noborder">
\(A=S\Lambda S^{-1}\)<br>
\(\Rightarrow A^2=S\Lambda (S^{-1}S)\Lambda S^{-1}\)<br>
\(\Rightarrow A^2=S\Lambda \mathcal{I}\Lambda S^{-1}\)<br>
\(\Rightarrow A^2=S\Lambda \Lambda S^{-1}\)<br>
\(\Rightarrow A^2=S\Lambda^2 S^{-1}\)<br>
where,
\(\Lambda^2=\begin{bmatrix}
 \lambda_1^2 &     0     & \cdots  &    0    \\  
 0         & \lambda_2^2 & \cdots  &    0    \\  
 \vdots    & \vdots    & \ddots  & \vdots    \\  
 0         &    0      & \cdots  &    \lambda_n^2    \\  
\end{bmatrix}\)
</blockquote>
Now we can get formula for \(k^{\text{th}}\) power of \(A\).<br>

<div class="l1 border">
    \[
        \begin{matrix}
            
        % equation
        \displaystyle A^k = S\Lambda^k S^{-1}
        %equation

        \end{matrix}
    \]
</div><br><blockquote>
So <i>eigenvectors</i> of \(A^k\) remains same as the <i>eigenvectors</i> of \(A\).<br>
But <i>eigenvalues</i> of \(A^k\) becomes \(\lambda^k\).<br>
</blockquote>
So now we can find power of matrices quickly, if we have the eigenvectors<i>(independent)</i> of that matrix.<br>


When we call a matrix \(A\) <b>stable</b>?<br>
<blockquote>
A matrix \(A\) is <b>stable</b> if \(A^k\to 0\) as \(k\to\infty\).<br>
And \(A^k\to 0\) as \(k\to\infty\) <b>if</b>,<br>
\(|\lambda_i| \lt 1;\quad\) \(\forall\ i\in\{1,2,\cdots n\}\)
</blockquote>

When a matrix \(A\) is <b>Diagonalizable?</b><br>
<blockquote>
<b>Diagonalizable</b> matrix has \(n\) <b>independent eigenvectors</b>.<br>
So \(A\) is <b>diagonalizable</b> if, all \(\lambda\)'s are different.<br>
\(\lambda_i\neq\lambda_j;\quad \forall \ i\neq j\)<br>
</blockquote>

<blockquote>
If all the <i>eigenvalues</i> are different then all the <i>eigenvectors</i> are <b>independent</b>.<br>
</blockquote>
<br>

<blockquote class="noborder">
<b>But</b> reverse is not true, <b>independence</b> of <i>eigenvectors</i> does <b>not</b>
implies that all <i>eigenvalues</i> are different.<br>
<b>Example</b><br>
Say \(A=\mathcal{I}_{3\times 3}=\begin{bmatrix}
 1      & 0 &    0    \\  
 0      & 1 &    0    \\  
 0      & 0 &    1 \\  
\end{bmatrix}\)<br>
So when we apply transformation of \(\mathcal{I}\) nothing changes so every vector is an eigenvector for \(\mathcal{I}\).<br>
But there is only <b>one</b> <i>eigenvalue</i> and that is \(1\).
</blockquote><br>
<br>

<h1><span class="bb">\(\vec{u}_{k+1}=A\vec{u}_k\)</span></h1>
Say we have a vector \(\vec{u}_0\) and a matrix(<b>non-singular</b>) \(A\), with \(n\) <b>independent</b> <i>eigenvectors</i>.<br>
We iteratively apply transformation \(A\) on \(\vec{u}_0\).<br>
\[\vec{u}_{k+1}=A\vec{u}_k\]
\(\vec{u}_{1}=A\vec{u}_0\)<br>
\(\vec{u}_2=A^2\vec{u}_0\)<br>
\(\vec{u}_k=A^k\vec{u}_0\)<br>
<br>
<h3>How can we find \(\vec{u}_k\) for an arbitrary large \(k\).</h3>
\(\vec{u}\) lives in the column space of \(A\), and \(A\) has \(n\) <b>independent</b> <i>eigenvectors</i>
so we can say that \(\vec{u}\) lives in the vector space spanned by these <i>eigenvectors</i>.<br>
so \(\vec{u}\) is the <b>linear combination</b> of these <i>eigenvectors</i>.<br>
say the <i>eigenvectors</i> of \(A\) are \(\vec{x}_1,\vec{x}_2,\cdots,\vec{x}_n\) 
and <i>eigenvalues</i> of \(A\) are \(\lambda_1,\lambda_2,\cdots,\lambda_n\) <br>
So we can say that,<br>
\(\vec{u}_0=c_1\vec{x}_1+c_2\vec{x}_2+\cdots+c_n\vec{x}_n\)<br>
\(\Rightarrow A\vec{u}_0=c_1A\vec{x}_1+c_2A\vec{x}_2+\cdots+c_nA\vec{x}_n\)<br>
\(\Rightarrow A\vec{u}_0=c_1\lambda\vec{x}_1+c_2\lambda\vec{x}_2+\cdots+c_n\lambda\vec{x}_n\)<br>
\(\Rightarrow A^{k}\vec{u}_0=c_1\lambda^{k}\vec{x}_1+c_2\lambda^{k}\vec{x}_2+\cdots+c_n\lambda^{k}\vec{x}_n\)<br>
\(\Rightarrow A^{k}\vec{u}_0=\Lambda^k S \vec{c}\)<br>
\(\Lambda=\begin{bmatrix}
 \lambda_1 &     0     & \cdots  &    0    \\  
 0         & \lambda_2 & \cdots  &    0    \\  
 \vdots    & \vdots    & \ddots  & \vdots    \\  
 0         &    0      & \cdots  &    \lambda_n    \\  
\end{bmatrix};\quad\)
\(S=\begin{bmatrix}
 \vdots & \vdots & \cdots & \vdots \\  
 \vec{x}_{1} & \vec{x}_{2} & \cdots &  \vec{x}_{n}   \\
 \vdots & \vdots & \cdots & \vdots \\
 \end{bmatrix};\quad\)
\(\vec{c}=\begin{bmatrix} c_1\\c_2\\ \vdots \\c_n \end{bmatrix}\)<br>
So,<br>
<div class="l1 border">
    \[
        \begin{matrix}
            
        % equation
        \displaystyle \vec{u}_k = A^{k}\vec{u}_0=\Lambda^k S\ \vec{c}
        %equation

        \end{matrix}
    \]
</div><br>

<br>

<h2 id="fibonacci">Fibonacci example</h2>
Fibonacci sequence: \(0,1,1,2,3,5,\cdots\)<br>
How can we find \(F_k\) for an arbitrary large \(k\).<br>
<span class="bb">\(F_{k+2}=F_{k+1}+F_k\)</span><br>
Now let's write it in form of <span class="bb">\(\vec{u}_{k+1}=A\vec{u}_k\)</span><br>
say \(\vec{u}_k= \begin{bmatrix} F_{k+1}\\F_k\\ \end{bmatrix}\)<br>
and \(\vec{u}_{k+1}=A\vec{u}_k\)<br>
\(\Rightarrow \vec{u}_{k+1}=A\begin{bmatrix} F_{k+1}\\F_k\\ \end{bmatrix}\)<br>
\(\Rightarrow A=\begin{bmatrix} 1&1\\1&0\\ \end{bmatrix}\)<br>
What are it's <i>eigenvalues</i> and <i>eigenvectors</i>.<br>
<blockquote class="noborder">

\(\text{det}(A - \lambda\mathcal{I})=\begin{vmatrix}
        1-\lambda & 1 \\
        1 & -\lambda \\
        \end{vmatrix}\)<br>
\(\text{det}(A - \lambda\mathcal{I})=\lambda^2-\lambda-1\)<br>
for \(\text{det}(A - \lambda\mathcal{I})=0\) we get,<br><br>
<span class="bb" style="padding-bottom: 20px; padding-top: 20px;">\(\lambda_1 = \frac{1+\sqrt{5}}{2}\)</span><br><br>
<span class="bb" style="padding-bottom: 20px; padding-top: 20px;">\(\lambda_2 = \frac{1-\sqrt{5}}{2}\)</span><br><br>
We get our <i>eigenvalues</i> \(\lambda_1, \lambda_2\).<br>
\((A-\lambda\mathcal{I})\vec{x}=0\)<br>
\(\begin{bmatrix}
        1-\lambda & 1 \\
        1 & -\lambda \\
        \end{bmatrix}
        \vec{x}=0
\)<br>
by solving it we get, <br>
\(\vec{x}=\begin{bmatrix} \lambda\\ 1 \end{bmatrix}\)<br>
So our <i>eigenvectors</i> are 
\(\vec{x}_1=\begin{bmatrix} \lambda_1\\ 1 \end{bmatrix},\quad\)
\(\vec{x}_2=\begin{bmatrix} \lambda_2\\ 1 \end{bmatrix}\)<br>
</blockquote><br>
Now we get our <i>eigenvectors</i> and <i>eigenvalues</i>.<br>
\(\vec{u}\) lives in the vector space spanned by these <i>eigenvectors</i>.<br>
so \(\vec{u}\) is the <b>linear combination</b> of these <i>eigenvectors</i>.<br>
we found the <i>eigenvectors</i> of \(A\) \(\vec{x}_1,\vec{x}_2\)
and <i>eigenvalues</i> of \(A\) are \(\lambda_1,\lambda_2\)<br>
So we can say that,<br>
\(\vec{u}_0=c_1\vec{x}_1+c_2\vec{x}_2\)<br>
\(\Rightarrow A\vec{u}_0=c_1A\vec{x}_1+c_2A\vec{x}_2\)<br>
\(\Rightarrow A\vec{u}_0=c_1\lambda_1\vec{x}_1+c_2\lambda_2\vec{x}_2\)<br>
So,<br>
<blockquote>
    <div class="math-container">
\[\vec{u}_k=A^{k}\vec{u}_0=c_1\left(\frac{1+\sqrt{5}}{2}\right)^{k}\vec{x}_1+c_2\left(\frac{1-\sqrt{5}}{2}\right)^{k}\vec{x}_2\]
</div>
</blockquote><br>
Now let's find \(c_1,c_2\).<br>
we know \(\vec{u}_0=\begin{bmatrix} F_{1}\\F_0\\ \end{bmatrix}\)<br>
\(\Rightarrow \vec{u}_0=\begin{bmatrix} 1\\0\\ \end{bmatrix}\)<br>
And we know that \(\vec{u}_0=c_1\vec{x}_1+c_2\vec{x}_2\) so,<br>
\(\vec{u}_0=c_1\begin{bmatrix} \lambda_1\\ 1 \end{bmatrix}+c_2\begin{bmatrix} \lambda_2\\ 1 \end{bmatrix}\)<br>
\(\Rightarrow c_1\begin{bmatrix} \lambda_1\\ 1 \end{bmatrix}+c_2\begin{bmatrix} \lambda_2\\ 1 \end{bmatrix}=\begin{bmatrix} 1\\0\\ \end{bmatrix}\)<br>
Now we got system of equations,<br>
\(c_1\lambda_1 + c_2\lambda_2 = 1\)<br>
\(c_1 + c_2 = 0\)<br>
by solving we get, \(c_1=\frac{1}{\lambda_1-\lambda_2}\) and \(c_2=\frac{-1}{\lambda_1-\lambda_2}\)<br>
\(\lambda_1-\lambda_2 = \frac{1+\sqrt{5}}{2} - \frac{1-\sqrt{5}}{2}=\sqrt{5}\)
we know that \(\vec{u}_k = A^k\vec{u}_0=c_1\lambda_1^k\vec{x}_1+c_2\lambda_2^k\vec{x}_2\)<br>
\(\Rightarrow \vec{u}_k =\frac{1}{\lambda_1-\lambda_2}\left(\lambda_1^k\vec{x}_1-\lambda_2^k\vec{x}_2\right)\)<br>
\(\Rightarrow \vec{u}_k =\frac{1}{\lambda_1-\lambda_2}\left(
            \lambda_1^k\begin{bmatrix} \lambda_1\\ 1 \end{bmatrix}-
            \lambda_2^k\begin{bmatrix} \lambda_2\\ 1 \end{bmatrix}\right)\)<br>
\(\Rightarrow \vec{u}_k =\frac{1}{\lambda_1-\lambda_2}\left(
            \begin{bmatrix} \lambda_1^{k+1}\\ \lambda_1^k \end{bmatrix}-
            \begin{bmatrix} \lambda_2^{k+1}\\ \lambda_2^k \end{bmatrix}\right)\)<br>
We know that, \(\vec{u}_k= \begin{bmatrix} F_{k+1}\\F_k\\ \end{bmatrix}\)<br>
So,<br>
\[F_k=\frac{\lambda_1^k - \lambda_2^k}{\lambda_1-\lambda_2}\]
\(\lambda_1 = \frac{1+\sqrt{5}}{2}\) and \(\lambda_2 = \frac{1-\sqrt{5}}{2}\) so<br>

<div class="l1 border math-container">
    \[
        \begin{matrix}
            
        % equation
        \displaystyle F_k=\frac{1}{\sqrt{5}}\left(   \left(\frac{1+\sqrt{5}}{2}\right)^k - \left(\frac{1-\sqrt{5}}{2}\right)^k  \right)
        %equation

        \end{matrix}
    \]
</div>
<blockquote>
For large \(k,\quad\) \(\left(\frac{1-\sqrt{5}}{2}\right)^{k}\approx 0\)<br>
So 
\[F_k\approx \frac{1}{\sqrt{5}}\left(   \left(\frac{1+\sqrt{5}}{2}\right)^k \right)\]
\(\frac{1+\sqrt{5}}{2}\) is known as <a style="color:#185EE0" href="https://en.wikipedia.org/wiki/Golden_ratio">Golden Ratio</a>
</blockquote><br>
<!--
Symmetric matrix will give us pure Real eigenvalue, and
Anti Symmetric matrix will give us pure Complex eigenvalue, and
-->
</p>



</div>
<div id="btn-container">
    <button id="prev-btn" class="button" onclick="window.location.href = '/linear-algebra/eigenvalues-eigenvectors/';">&#x25C0;&nbsp;&nbsp;Eigenvalues and Eigenvectors</button>
    <button id="next-btn" class="button"  style="float: right;" onclick="window.location.href = '/linear-algebra/differential-equation/';">Differential Equation&nbsp;&nbsp;&#x25B6;</button>
</div><br>
    <div id="modals-html"></div>

</section>
</div><!-- Main [END]-->
</div><!-- Wrapper [END]-->
<script>requireScript('script-js', '0.1.0', '/data/js/script.js', function(){cssLoaded()})</script>

</body>
</html>