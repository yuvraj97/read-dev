<!DOCTYPE HTML>
<html lang="en">

	<head>

		<link rel="stylesheet" href="/data/css/main.css">

		<title>Central Limit Theorem | Fundamentals of Statistics - QuantML</title>
		<meta charset="utf-8" />
		<link rel="icon" href="/data/icon.png" type="image/png" sizes="16x16">
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<meta name="robots" content="index, follow">

		<script src="/data/js/initialize.js"></script>

		<script>
			var nextPage = "/statistics/gaussian-distribution/";
			var prevPage = "/statistics/weak-law-of-large-numbers/";
			var nextPageTitle = "Gaussian Distribution";
			var prevPageTitle = "Law of Large Numbers";
			var arrowLeftPage = "/statistics/weak-law-of-large-numbers/julia/";
			var arrowRightPage = "/statistics/central-limit-theorem/python/";
			window.quantml["chapterID"] = "central-limit-theorem"
		</script>
	</head>

	<body>

		<!-- Wrapper -->
			<div style="display: none;" id="wrapper">
				<div class="bg fixed" style="transform: none;"></div>
				<div id="navPanelToggle">Menu</div>

				<!-- Header -->
				<header id="header">
					<a href="https://quantml.org" style="display: none;" class="logo image jump-big" id="quantml-cover-light"><img src="/data/img/cover.webp" alt="QuantML.org" /></a>
					<a href="https://quantml.org" style="display: none;" class="logo image jump-big" id="quantml-cover-dark"><img src="/data/img-dark/cover.webp" alt="QuantML.org" /></a>
					<script>if(window.quantml["theme"]=="dark") document.getElementById('quantml-cover-dark').style.display = "block";else document.getElementById('quantml-cover-light').style.display = "block";</script>
				</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li class="cover"><a href="/statistics/"><img src="/data/img/STATISTICS-cover.webp" alt="STATISTICS"></a></li>
							<li class="active title">Central Limit Theorem</li>
							<li class="python"><a href="/statistics/central-limit-theorem/python/"><img src="/data/img/python.webp" alt="Python"></a></li>
							<li class="julia"><a href="/statistics/central-limit-theorem/julia/"><img src="/data/img/julia.webp" alt="Julia"></a></li>
						</ul>
					</nav>

<!-- Main -->
<div id="main">
    <section class="post">
<div style="text-align: center;" id="load-init"></div>
<script>initializeBody();</script>

<div id="paragraph-content" data-swipe-threshold="80">

<div id="desktop-mode">
	<div id="btn-container"></div><br>
</div>


<h1 id="central-limit-theorem">Central Limit Theorem<a href="#central-limit-theorem" aria-label="central-limit-theorem"><i class="fa fa-link" aria-hidden="true"></i></a></h1>
<blockquote class="noborder align-center">
	<a rel="noreferrer" target="_blank" href="https://app.quantml.org/statistics/?ch=Central-Limit-Theorem&dist=Uniform+distribution">
		Visualize Central Limit Theorem <img src="/data/img/app.webp" alt="launch" width="30px" height="30px">
	</a>
</blockquote>

<!-- <a href="/statistics/weak-law-of-large-numbers/">Previously in Weak Law of Large Numbers</a> we discussed that as our <b>sample size</b> <div class="quantml-katex-display inline">\((n)\to\infty\)</div> our <b>sample mean</b> <div class="quantml-katex-display inline">\((\overline{X}_n)\to\)</div> <b>true mean</b> <div class="quantml-katex-display inline">\((\mu)\)</div>. <br> -->
<blockquote class="sidebar">
<a href="/statistics/weak-law-of-large-numbers/#main">Continuing previous example</a>, <!--in previous example--> we discussed how <a href="/statistics/weak-law-of-large-numbers/#main">Weak Law of Large Numbers</a> helps us getting the average height of students. Remember that the average height we calculated <div class="quantml-katex-display inline">\((\overline{X}_n)\)</div> is a <b>random variable</b>, so it must have an underlying probability distribution and we don't know what that distribution is. <b>Central Limit Theorem</b> helps us to approximate that unknown distribution. Once we know the underlying distribution we can answer a lot of questions.<br>
</blockquote><br>
<h2 id="introduction">Introduction<a href="#introduction" aria-label="introduction"><i class="fa fa-link" aria-hidden="true"></i></a></h2>
Say we have a large population <!--Add hover over to specify what is population--> and we took a <b>sample</b> out of that population, and we want to study the <b>distribution</b> of the <b>average</b> of some specific property of that sample. <br>
<blockquote class="sidebar">
	For example say we want to study the average height of students in our class.
</blockquote>
Central Limit Theorem(CLT) <!--Had over cover--> helps us in this. CLT says:
<blockquote>
	No matter what distribution(with finite mean and variance) our <b>population</b> follows, as we increase sample size, <b>Sampling distribution</b> of the  mean <b>converges</b> to a <a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal distribution</a>.
</blockquote>

<h3 id="sampling-distribution-of-the-mean" class="bold" style="margin-top: 20px;">Sampling Distribution of the Mean<a href="#sampling-distribution-of-the-mean" aria-label="sampling-distribution-of-the-mean"><i class="fa fa-link" aria-hidden="true"></i></a></h3>
Say you collected <b>multiple</b> samples (of same sample size) out of the population, then you take the average of all of those samples, and then you plot a histogram of those sample averages. This histogram is what we are referring as Sampling distribution of the mean. <br>
Fortunately, we don't need <b>multiple</b> samples. CLT helps us to approximate sampling distribution with just one sample. <br>
We only have to take care that our sample size is sufficiently large. <br>
Now the question arises, how large should our sample size be (say <div class="quantml-katex-display inline">\(n\)</div>)? <br>
<blockquote class="noborder">
	<b>Rule of thumb</b>: If our distribution is symmetric around mean then <div class="quantml-katex-display inline">\(n\geq 30\)</div> is sufficient to apply Central Limit Theorem.
</blockquote>

<h4 class="bold" style="margin-top: 20px;"> But remember it's just a rule of thumb!</h4>
	<blockquote class="sidebar">
		The more the true distribution varies from the Normal distribution, the larger sample size is required.<br>
		If the distribution is not symmetric around mean, then <div class="quantml-katex-display inline">\(n\geq 30\)</div> might not be near to sufficient! <br>
		What you can do is, plot the <b>CDF</b> of your data and superimpose <b>CDF</b> of corresponding Normal distribution, and see that do they superimpose nicely?
		(We have covered <this> it in our
		<a href="/statistics/central-limit-theorem/python/">Python</a> /
		<a href="/statistics/central-limit-theorem/julia/">Julia</a>
		simulation.)
</blockquote>
<blockquote class="noborder">
Definition of nicely is up to you, how much error are you willing to accept. <br>
You can also use some statistical test to check if our Sampling distribution matches the Normal distribution (like <!-- Future Link --> Kolmogorovâ€“Smirnov test). We will cover these tests in this guide.
</blockquote>
<br>

<h2 id="convergence-of-sampling-distribution">Convergence of Sampling Distribution<a href="#convergence-of-sampling-distribution" aria-label="convergence-of-sampling-distribution"><i class="fa fa-link" aria-hidden="true"></i></a></h2>
Now let's say we have a population and we draw <div class="quantml-katex-display inline">\(n\)</div> random <b>I.I.D.</b> <!--Add hover over to specify what is iid--> observations <div class="quantml-katex-display inline">\(X_1,X_2,\cdots,X_n\)</div> from it. <br>
These <div class="quantml-katex-display inline">\(n\)</div> <b>I.I.D.</b> observations are result of some random process with <b>unknown</b> distribution. This random process has a finite mean say <div class="quantml-katex-display inline">\((\mu)\)</div> and a finite variance say <div class="quantml-katex-display inline">\((\sigma^2)\)</div>. <br>

<span class="bb"> <div class="quantml-katex-display inline">\(\mathbb{E}[X]=\mu\)</div></span>  and <span class="bb"> <div class="quantml-katex-display inline">\(Var(X)=\sigma^2\)</div> </span><br>
Estimator we used for <div class="quantml-katex-display inline">\(\mu\)</div> is <div class="quantml-katex-display inline">\(\overline{X}_n=\frac{1}{n}\left(X_1+X_2+\cdots+X_n\right)\)</div>. <br>
And according to <a href="/statistics/weak-law-of-large-numbers/">Weak Law of Large Numbers</a> <span class="bb math"><div class="quantml-katex-display inline">\(\overline{X}_n \xrightarrow [n\to \infty ] {\mathbb{P}} \mu\)</div></span>

<details>
	<summary><span class="bb math"><div class="quantml-katex-display inline">\(\displaystyle\text{Var}(\overline{X}_n)=\frac{\sigma^2}{n}\)</div></span></summary>
	<blockquote class="sidebar">
		<div class="quantml-katex-display inline">\(\displaystyle\text{Var}(\overline{X}_n)=\text{Var}\left(\frac{1}{n}\left(X_1+X_2+\cdots+X_n\right)\right)\)</div>
		<div style="margin-bottom: 15px; margin-top: 10px;">
			<div class="quantml-katex-display inline">\(\displaystyle\text{Var}(\overline{X}_n) = \frac{1}{n^2}(\text{Var}(X_1) + \text{Var}(X_2) + \cdots + \text{Var}(X_n))\)</div>
		</div>
		<div style="margin-bottom: 15px; margin-top: 10px;">
			<div class="quantml-katex-display inline">\(\displaystyle\text{Var}(\overline{X}_n) = \frac{1}{n^2}(\underbrace{\sigma^2 + \cdots + \sigma^2}_{\text{n times}}  )\)</div>
		</div>
		<div style="margin-bottom: 10px;">
			<div class="quantml-katex-display inline">\(\displaystyle\text{Var}(\overline{X}_n) = \frac{1}{n^2}(n\sigma^2)\)</div> <br>
		</div>
			<span class="bb math"><div class="quantml-katex-display inline">\(\displaystyle\text{Var}(\overline{X}_n)=\frac{\sigma^2}{n}\)</div></span>
	</blockquote>
</details>

Here we can see as <div class="quantml-katex-display inline">\(n\to \infty\)</div>, <div class="quantml-katex-display inline">\(\text{Var}(\overline{X}_n)\to 0\)</div>, then as a consequence, the probability distribution of <div class="quantml-katex-display inline">\(\overline{X}_n\)</div> is highly concentrated in an arbitrarily small interval around mean <div class="quantml-katex-display inline">\(\mu\)</div>. So this probability distribution doesn't help us in any way, as it's totally concentrated around one number <div class="quantml-katex-display inline">\(\mu\)</div>. <br>
<br>

<li> Now let's look at the distribution of <span class="bb math"><div class="quantml-katex-display inline">\(\sqrt{n}\ \overline{X}_n\)</div></span>. </li>
<blockquote class="sidebar">
<span class="bb math"><div class="quantml-katex-display inline">\(\displaystyle\text{Var}(\sqrt{n}\overline{X}_n)=\sigma^2\)</div></span> for the distribution of <div class="quantml-katex-display inline">\(\sqrt{n}\ \overline{X}_n\)</div>, variance remains unchanged. <br>

<span class="bb math"><div class="quantml-katex-display inline">\(\displaystyle\mathbb{E}[\sqrt{n}\overline{X}_n]=\sqrt{n}\mu\)</div></span> but <div class="quantml-katex-display inline">\(\mathbb{E}[\sqrt{n}\overline{X}_n] \xrightarrow [n\to \infty ]{} \infty\)</div>, so let's center the distribution around <div class="quantml-katex-display inline">\(0\)</div>.
</blockquote><br>

<li> Now let's look at the distribution of <span class="bb math"><div class="quantml-katex-display inline">\(\sqrt{n}\ (\overline{X}_n - \mu)\)</div></span>. </li>
<blockquote class="sidebar">
<span class="bb math"><div class="quantml-katex-display inline">\(\displaystyle\text{Var}\left(\sqrt{n}\ (\overline{X}_n - \mu)\right)=\sigma^2\)</div></span>
<span class="bb math"><div class="quantml-katex-display inline">\(\displaystyle\mathbb{E}\left[\sqrt{n}\ (\overline{X}_n - \mu)\right]=0\)</div></span><br>
Now there is no effect of <div class="quantml-katex-display inline">\(n\)</div> on both the variance and the expectation of the distribution of <div class="quantml-katex-display inline">\(\sqrt{n}\ (\overline{X}_n - \mu)\)</div>. <br>
</blockquote>

<li> Now let's look at the distribution of <span class="bb math"><div class="quantml-katex-display inline">\(\displaystyle\sqrt{n}\ \left( \frac{\overline{X}_n - \mu}{\sigma} \right)\)</div></span>. </li>
<blockquote class="sidebar">
<span class="bb math"><div class="quantml-katex-display inline">\(\displaystyle\text{Var}\left(\sqrt{n}\ \left( \frac{\overline{X}_n - \mu}{\sigma} \right)\right)=1\)</div></span>
<span class="bb math"><div class="quantml-katex-display inline">\(\displaystyle\mathbb{E}\left[\sqrt{n}\ \left( \frac{\overline{X}_n - \mu}{\sigma} \right)\right]=0\)</div></span><br>
Now we have standardize our random variable <div class="quantml-katex-display inline">\(\overline{X}_n\)</div> for every <b>mean</b><div class="quantml-katex-display inline">\((\mu)\)</div>, <b>variance</b><div class="quantml-katex-display inline">\((\sigma^2)\)</div> and <b>sample size</b><div class="quantml-katex-display inline">\((n)\)</div>.<br>
</blockquote><br>
Say <div class="quantml-katex-display inline">\(Z_n := \displaystyle\sqrt{n}\ \left( \frac{\overline{X}_n - \mu}{\sigma} \right)\)</div>, and <div class="quantml-katex-display inline">\(Z\sim\mathcal{N}(0,1)\)</div>. <br>
(<div class="quantml-katex-display inline">\(Z\)</div> is a standard normal random variable with mean <div class="quantml-katex-display inline">\(0\)</div> and variance <div class="quantml-katex-display inline">\(1\)</div>). <br>
Now <b>Central Limit Theorem</b> states,
<blockquote>
	For every <div class="quantml-katex-display inline">\(z:\)</div>
	<div class="quantml-katex-display">\[\lim_{n\to\infty}\mathbb{P}(Z_n \lt z) = \mathbb{P}(Z \lt z)\]</div>
	<div class="quantml-katex-display">\[\sqrt{n}\, \frac{\overline{X}_n-\mu }{\sigma } \xrightarrow [n\to \infty ]{(d)} \mathcal{N}(0,1) \]</div><br>
</blockquote>
So Central Limit Theorem says that, as <div class="quantml-katex-display inline">\(n\to \infty\)</div> then <b>CDF</b>(<a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">cumulative distribution function</a>) of the random variable <div class="quantml-katex-display inline">\(Z_n\)</div> converges to the <b>CDF</b> of standard normal random variable <div class="quantml-katex-display inline">\(Z\)</div>. <br>

<blockquote id="its-about-CDF">
	So <b>Central Limit Theorem</b> is a statement about the convergence of <b>CDF</b>, it's <b>not</b> a statement about the convergence of <a href="https://en.wikipedia.org/wiki/Probability_density_function">PDF</a> or <a href="https://en.wikipedia.org/wiki/Probability_mass_function">PMF</a>.

	<!-- CLARIFICATION BY PLOTS!!! -->
</blockquote>

<!-- <h3>Can we use Central Limit Theorem when <div class="quantml-katex-display inline">\(n\)</div> is "moderate"?</h3>
In real life we don't have <div class="quantml-katex-display inline">\(\infty\)</div> observations, maybe <div class="quantml-katex-display inline">\(n\)</div> is <div class="quantml-katex-display inline">\(30\)</div> or <div class="quantml-katex-display inline">\(20\)</div> or <div class="quantml-katex-display inline">\(15\)</div> can we use <b>CLT</b>? -->

<blockquote class="sidebar">
	<b>Rule of thumb to apply CLT</b>: when <div class="quantml-katex-display inline">\(n\geq 30\)</div> then <div class="quantml-katex-display inline">\(\sqrt{n}\, \frac{\overline{X}_n-\mu }{\sigma } \xrightarrow []{(d)} \mathcal{N}(0,1) \)</div>
</blockquote><br>

<h2 id="rate-of-convergence">Rate of Convergence<a href="#rate-of-convergence" aria-label="rate-of-convergence"><i class="fa fa-link" aria-hidden="true"></i></a></h2>
Now we can finally answer our <a href="/statistics/weak-law-of-large-numbers/#how-fast">previous question</a> in <a href="/statistics/weak-law-of-large-numbers/">Weak Law of Large Numbers</a> that, 
how fast(at what rate) <div class="quantml-katex-display inline">\(\overline{X}_n\)</div> approaches to <div class="quantml-katex-display inline">\(\mu\)</div>. <br>

If we draw a standard gaussian  <div class="quantml-katex-display inline">\(\mathcal{N}(0,1) \)</div> (say) <div class="quantml-katex-display inline">\(Z\)</div>, then with probability <div class="quantml-katex-display inline">\(0.9974,\)</div>  <div class="quantml-katex-display inline">\(Z\in [-3,3]\)</div><br>
<div class="quantml-katex-display inline">\(P(-3\leq Z\leq3)=0.9974\)</div>  (we can calculate it <a rel="noreferrer" target="_blank" href="https://www.mathportal.org/calculators/statistics-calculator/normal-distribution-calculator.php">here</a>).<br>
So <div class="quantml-katex-display inline">\(Z\)</div> is almost in between -3 and 3<br>
And we know that :<br>
<div class="quantml-katex-display">\[\sqrt{n}\, \frac{\overline{X}_n-\mu }{\sigma } \xrightarrow [n\to \infty ]{(d)} \mathcal{N}(0,1) \]</div><br>
And we say that <div class="quantml-katex-display inline">\(-3\leq\mathcal{N}(0,1)\leq3\)</div><br>
So:<br>
<div class="quantml-katex-display">\[
-3\leq \sqrt{n}\, \frac{\overline{X}_n-\mu }{\sigma }  \leq3 \\
\Rightarrow  \left|\sqrt{n}\, \frac{\overline{X}_n-\mu }{\sigma } \right| \leq 3	\\
\Rightarrow \left| \overline{X}_n-\mu  \right| \leq \frac{3\sigma}{\sqrt{n}}
\]</div><br>
<span class="bb" id="sqrt-n">So according to CLT <div class="quantml-katex-display inline">\(f(n)=\sqrt{n}\)</div></span><br>
<br>

<blockquote class="noborder align-center">
	Now let's see some Simulation, choose your language of choice,<br>
	<a href="/statistics/central-limit-theorem/python/"><img src="/data/img/python.webp" alt="Python" width="75px" height="20px"></a> &nbsp;,&nbsp;
	<a href="/statistics/central-limit-theorem/julia/"><img src="/data/img/julia.webp" alt="Julia" width="53px" height="33px"></a>
	<br>
	<a rel="noreferrer" target="_blank" href="https://app.quantml.org/statistics/?ch=Central-Limit-Theorem&dist=Uniform+distribution">Launch Statistics App <img src="/data/img/app.webp" alt="launch" width="30px" height="30px"></a>
</blockquote><br>




<div id="btn-container"></div><br>
<br>
<blockquote class="sidebar" style="padding-bottom: 0%;">
	<h3>Recommended Watching</h3>

	<details style="margin-top: 10px; margin-bottom: 10px;" id="recommended-watchings-1">
		<summary><i><span style="text-align: center;" class="bb">Central Limit Theorem</span> (by Prof. John Tsitsiklis)</i></summary>
			<img style="display: none; margin-top: 1rem;" id="loading-iframe-1" class="loading" src="/data/img/loading.svg" alt="">
			<div id="recommended-watchings-1-iframe" style="text-align: center; margin-top:10px;"></div>
	</details>

	<details style="margin-top: 10px; margin-bottom: 10px;" id="recommended-watchings-2">
		<summary><i><span style="text-align: center;" class="bb">Central Limit Theorem</span> (by Khan Academy)</i></summary>
			<img style="display: none; margin-top: 1rem;" id="loading-iframe-2" class="loading" src="/data/img/loading.svg" alt="">
			<div id="recommended-watchings-2-iframe" style="text-align: center; margin-top:10px;"></div>
	</details>

	<details style="margin-top: 10px; margin-bottom: 10px;" id="recommended-watchings-3">
		<summary><i><span style="text-align: center;" class="bb">Central Limit Theorem</span> (by Sir Josh Starmer)</i></summary>
			<img style="display: none; margin-top: 1rem;" id="loading-iframe-3" class="loading" src="/data/img/loading.svg" alt="">
			<div id="recommended-watchings-3-iframe" style="text-align: center; margin-top:10px;"></div>
	</details>

	<details style="margin-top: 10px; margin-bottom: 10px;" id="recommended-watchings-4">
		<summary><i><span style="text-align: center;" class="bb">Central Limit Theorem</span> (by Sir Jeremy Balka)</i></summary>
			<img style="display: none; margin-top: 1rem;" id="loading-iframe-4" class="loading" src="/data/img/loading.svg" alt="">
			<div id="recommended-watchings-4-iframe" style="text-align: center; margin-top:10px;"></div>
	</details>

		<details style="margin-top: 10px; margin-bottom: 10px;" id="recommended-watchings-5">
		<summary><i><span style="text-align: center;" class="bb">Real-world application of the CLT</span> (by 365 Data Science)</i></summary>
			<img style="display: none; margin-top: 1rem;" id="loading-iframe-5" class="loading" src="/data/img/loading.svg" alt="">
			<div id="recommended-watchings-5-iframe" style="text-align: center; margin-top:10px;"></div>
	</details>

	<br>
	</blockquote>

<br><br>
</div>
<div id="modals-html"></div>

</section>
</div><!-- Main [END]-->
</div><!-- Wrapper [END]-->
<script>requireScript('script-js', '0.1.0', '/data/js/script.js', function(){cssLoaded()})</script>

</body>
</html>